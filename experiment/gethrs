#!/Users/thedrub/anaconda3/bin/python

import pandas as pd
import sys
import csv
import os

# ----------------------------------------------------------------------
# Files
# ----------------------------------------------------------------------
input_file_path = "gethrs_input.txt"
HOME = os.environ['HOME'] # Use the $HOME env variable
input_file_path = HOME + "/Sync/doc/journal/work/work_journal_file.txt"
output_file_path = "./gethrs_output.csv"

# ----------------------------------------------------------------------
# Constants
# ----------------------------------------------------------------------
# TODO :: Turn these seperate variables into a dictionary
prog_config = \
    {"name"     : sys.argv[0], \
    "maj_ver"   : "1", \
    "min_ver"   : "0", \
    }
prog_config["ver"] = prog_config["maj_ver"] + "." + prog_config["min_ver"]

TOKEN_COUNT_VER_4_dot_1 = 11  # The number of records in record ver 4.1
SEP_LN_LEN = 70               # Seperator line length
PLUS_LINE_LENGTH = 20         # Leading line for an error

# --------------------------------------------------
def Display_tokens(token_list):
# --------------------------------------------------
    i = 0
    for token in tokens:
        print ("[{0:2}] ... {1}".format(i, token))
        i += 1 

# ----------------------------------------------------------------------
# Main MAIN main
# ----------------------------------------------------------------------
print ("++ " + prog_config["name"]  + " " + prog_config["ver"])
debug = False
debug = True

line_counter = 0

if debug:
    print ("++ Program name .............. " + prog_config["name"])
    print ("++ Program version ........... " + prog_config["ver"])
    print ('++ Number of arguments ....... ', len(sys.argv))
    print ('++ Argument List:', str(sys.argv))

#exit() #debug

column_names=["lineno",\
              "rec_type",\
              "rec_ver",\
              "day",\
              "date",\
              "start",\
              "end",\
              "duration",\
              "customer",\
              "rec_state",\
              "comment",\
              "remainder"]
df = pd.DataFrame(columns = column_names)
#print ("++ df info", df.info) #debug

with open(input_file_path, 'r') as in_fd:
    for line in in_fd:
        line = line.rstrip('\r\n') # Strip the trailing EOL
        line_counter += 1

        tokens = line.split("::")
        token_count = len(tokens) # Count only the tokens from the input file.

        if (tokens[0] == "TIME") :

            # A TIME:: record was found.
            # Process token for record version 4.1 only
            # Deprecate earlier record versions with this new implementation

            #print ("++ " + "-"*sep_ln_len) #debug
            #print(f"++ Line ..................... {line_counter}") #debug
            #print("++ Comment field ............. ", tokens[9]) #debug

            # Record the input file line number in the record.
            tokens.insert(0, line_counter) 

            #print ("++ token count ............... ", token_count) #debug
            #print ("++ tokens: ", tokens) #debug

            debug = True    #debug
            debug = False    #debug
            if debug == True :
                print ("+" * PLUS_LINE_LENGTH)
                Display_tokens(tokens)

            record_ver  = tokens[1]   # Capture the record version

            if token_count != TOKEN_COUNT_VER_4_dot_1 :
                print ("+" * PLUS_LINE_LENGTH)
                print ("++ Bad record. Token count mismatch.")
                print ("++ Expected " + str(TOKEN_COUNT_VER_4_dot_1) + " tokens.")
                print ("++ Line " + str(tokens[0]) + " has " + str(len(tokens)) \
                      + " tokens.")  
                #print ("++ tokens: ", tokens) #debug
                Display_tokens(tokens)

            else:
                record_state = tokens[9]
                if (record_state == "new") :
                    # Print records not yet entered into Jira
                    print (tokens)

                # Add the tokens list to the end of the dataframe
                df.loc[len(df)] = tokens
                #print (f"++ df length ................. {len(df)}") #debug

#print("++ df: ") #debug
#print(df) #debug
print (f"++ Records added ............. {len(df)}") #debug

df.to_csv(output_file_path, index = False)

#in_fd.close()
#out_fd.close()
exit()

# ----------------------------------------------------------------------
# End END end
# ----------------------------------------------------------------------


'''
# ----------------------------------------------------------------------
# TODO
# ----------------------------------------------------------------------

- Default to writing to csv only records for the last 2 weeks

- Add a -a parameter, "all",  that writes to stdout records with any
  record_state and not just limited to the "a" state.

- Add a -c parameter, "count", that writes a fixed number of records to stdout,
  and not limited to the default number of records.

- Add a -cc parameter, "csv count", that outputs a fixed number of records
  to the csv file.  

# ----------------------------------------------------------------------
# History
# ----------------------------------------------------------------------

# --------------------------------------------------
# Ver: 1.0
# --------------------------------------------------
Record versions supported: 4.0

- Parses the input file for supported records
- Writes to stdout records with record_state = "a"
- Writes all TIME:: records to a csv file.
  - Input file name hard coded

'''
